*EN*

# Sentiment Analysis ‚Äî EDA


This notebook performs exploratory data analysis (EDA) on the [IMDB Sentiment Dataset](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).

## Objective

To understand the structure and characteristics of movie reviews and their associated sentiments in order to build a predictive model that classifies reviews as **positive** or **negative**.

To build and compare two models using:
- **TF-IDF + Logistic Regression / Naive Bayes**
- **Word2Vec Embeddings + Random Forest**

The goal is to identify which approach provides better generalization for sentiment classification.

---

## Project Structure

imdb-sentiment-analysis-nlp/

‚îú‚îÄ‚îÄ data/ # Raw dataset

‚îú‚îÄ‚îÄ notebooks/EDA.ipynb # Exploratory analysis, visualization

‚îú‚îÄ‚îÄ src/

‚îÇ ‚îú‚îÄ‚îÄ preprocess.py # Preprocessing for TF-IDF and Word2Vec

‚îÇ ‚îú‚îÄ‚îÄ train_td-idf.py # Training with TF-IDF

‚îÇ ‚îî‚îÄ‚îÄ train_w2v.py # Training with Word2Vec

‚îú‚îÄ‚îÄ plots/ # ROC, confusion matrix, barplots

‚îú‚îÄ‚îÄ models/ # Saved models, vectorizers, metrics

‚îî‚îÄ‚îÄ README.md

---

## Dataset Overview

- **Shape:** 50,000 rows √ó 2 columns (`review`, `sentiment`)
- **Target:** `sentiment` ‚Äî Binary classification (`positive`, `negative`)
- **Balance:** Perfectly balanced (25,000 positive / 25,000 negative)
- **Languages:** All reviews in English

---

## Initial Analysis

- Verified data types and checked for missing values ‚Äî none found
- Text column: `review` is stored as `object`
- Target column: `sentiment` contains only two classes

---

## Text Cleaning

Applied the following cleaning steps to create a new column `clean_text`:
- Lowercased all words
- Removed HTML tags (`<br />`, etc.)
- Removed punctuation and digits
- Removed English stop-words using NLTK
- Tokenization  
- Bigrams for Word2Vec

Also computed a new feature:
- `review_length` ‚Äî number of words in each cleaned review
- `clean_text` ‚Äî cleaned version of reviews

---

## Visual Explorations

### Review Length Distribution

Distribution of review lengths: most between **100‚Äì400 words**

![Review Length](./plots/review_length_distribution.png)

###  Top frequent words and bigrams per class

![Top Words](./plots/positive_negative_words.png)


### WordClouds for positive/negative sentiment


- Positive:

  ![Positive WordCloud](./plots/positive_wordcloud.png)

- Bigrams in Positive Reviews:

  ![Positive Bigrams](./plots/positive_bigrams_wordcloud.png)

- Bigrams in Negative Reviews:

  ![Negative Bigrams](./plots/negative_bigrams_wordcloud.png)


**Class balance is perfect (50/50)**

---

### üîπ Word Frequency Analysis

Top 20 most common words by class:

| Positive | Negative |
|----------|----------|
| great    | bad      |
| best     | worst    |
| love     | boring   |
| story    | waste    |
| ...      | ...      |

---

## Insights

- Reviews are relatively balanced in length across classes
- Certain strong words ("best", "amazing", "worst", "boring") are strong indicators of sentiment
- Bigrams like `"one best"`, `"ever seen"` are common in positive reviews

---

## Model Training & Evaluation

### TF-IDF Models
- **Logistic Regression**
- **Multinomial Naive Bayes**

Vectorizer: `TfidfVectorizer(max_features=20000, ngram_range=(1, 2))`

### Word2Vec Model
- Trained using `gensim.models.Word2Vec`
- Averaged embeddings
- Classifier: **Random Forest**

---

## Evaluation Metrics

| Model                            | Accuracy | ROC AUC |
|----------------------------------|----------|---------|
| Logistic Regression (TF-IDF)     | 0.91     | 0.96    |
| Naive Bayes (TF-IDF)             | 0.87     | 0.93    |
| Random Forest (Word2Vec)         | 0.85     | 0.91    |

Stored in:
- `td-idf_metrics.json`
- `w2v_metrics.json`

---

## Visual Comparison

### ROC Curves

![ROC Comparison](./plots/roc_comparison.png)

### Confusion Matrices

![Confusion Matrices](./plots/conf_matrix.png)

### Barplots: Accuracy & AUC

![Metric Comparison](./plots/metric_comparison.png)

---

## Saved Artifacts

Models and metrics saved to `/models/`:
- `sentiment_model.pkl`
- `tfidf_vectorizer.pkl`
- `td-idf_metrics.json`
- `w2v_clf.pkl`
- `w2v_embedding.model`
- `w2v_metrics.json`

---

## Summary

- TF-IDF + Logistic Regression is the most accurate and interpretable
- Naive Bayes performs well and trains very fast
- Word2Vec + Random Forest has promise, but needs more tuning
- Text preprocessing is essential for performance

---

*EN*

# –ê–Ω–∞–ª–∏–∑ ‚Äî EDA

–í —ç—Ç–æ–º –±–ª–æ–∫–Ω–æ—Ç–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ä–∞–∑–≤–µ–¥–æ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (EDA) –Ω–∞ –æ—Å–Ω–æ–≤–µ [–Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ IMDB](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).

## –¶–µ–ª—å

–ü–æ–Ω—è—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±–∑–æ—Ä–æ–≤ —Ñ–∏–ª—å–º–æ–≤ –∏ —Å–≤—è–∑–∞–Ω–Ω—É—é —Å –Ω–∏–º–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –æ–±–∑–æ—Ä—ã –∫–∞–∫ **–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ** –∏–ª–∏ **–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ**.

–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–µ –º–æ–¥–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É—è:
- **TF-IDF + –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é / –Ω–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º**
- **Word2Vec Embeddings + —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å**

–¶–µ–ª—å ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–∞–∫–æ–π –ø–æ–¥—Ö–æ–¥ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ª—É—á—à–µ–µ –æ–±–æ–±—â–µ–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.

---

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

imdb-sentiment-analysis-nlp/

‚îú‚îÄ‚îÄ data/ # Raw dataset

‚îú‚îÄ‚îÄ notebooks/EDA.ipynb # –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

‚îú‚îÄ‚îÄ src/

‚îÇ ‚îú‚îÄ‚îÄ preprocess.py # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è TF-IDF –∏ Word2Vec

‚îÇ ‚îú‚îÄ‚îÄ train_td-idf.py # –û–±—É—á–µ–Ω–∏–µ —Å TF-IDF

‚îÇ ‚îî‚îÄ‚îÄ train_w2v.py # –û–±—É—á–µ–Ω–∏–µ —Å Word2Vec

‚îú‚îÄ‚îÄ plots/ # ROC, confusion matrix, barplots

‚îú‚îÄ‚îÄ models/ # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏, –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä—ã, –º–µ—Ç—Ä–∏–∫–∏

‚îî‚îÄ‚îÄ README.md

---

## –û–±–∑–æ—Ä –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö

- **–§–æ—Ä–º–∞:** 50 000 —Å—Ç—Ä–æ–∫ √ó 2 —Å—Ç–æ–ª–±—Ü–∞ (`review`, `sentiment`)
- **–¶–µ–ª—å:** `sentiment` ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (`positive`, `negative`)
- **–ë–∞–ª–∞–Ω—Å:** –ò–¥–µ–∞–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω (25 000 –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö / 25 000 –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö)
- **–Ø–∑—ã–∫–∏:** –í—Å–µ –æ—Ç–∑—ã–≤—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ

---

## –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑

- –ü—Ä–æ–≤–µ—Ä–µ–Ω—ã —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ
- –¢–µ–∫—Å—Ç–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü: `review` —Ö—Ä–∞–Ω–∏—Ç—Å—è –∫–∞–∫ `object`
- –¶–µ–ª–µ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü: `sentiment` —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –¥–≤–∞ –∫–ª–∞—Å—Å–∞

---

## –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞

–ü—Ä–∏–º–µ–Ω–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –æ—á–∏—Å—Ç–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ `clean_text`:
- –í—Å–µ —Å–ª–æ–≤–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
- –£–¥–∞–ª–µ–Ω—ã HTML-—Ç–µ–≥–∏ (`<br />` –∏ —Ç. –¥.)
- –£–¥–∞–ª–µ–Ω—ã –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ —Ü–∏—Ñ—Ä—ã
- –£–¥–∞–ª–µ–Ω—ã –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ —Å –ø–æ–º–æ—â—å—é NLTK
- –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
- –ë–∏–≥—Ä–∞–º–º—ã –¥–ª—è Word2Vec

–¢–∞–∫–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω –Ω–æ–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫:
- `review_length` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –∫–∞–∂–¥–æ–º –æ—á–∏—â–µ–Ω–Ω–æ–º –æ—Ç–∑—ã–≤–µ
- `clean_text` ‚Äî –æ—á–∏—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ—Ç–∑—ã–≤–æ–≤

---

## –í–∏–∑—É–∞–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—Ç–∑—ã–≤–æ–≤

–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –æ—Ç–∑—ã–≤–æ–≤: –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –æ—Ç **100 –¥–æ 400 —Å–ª–æ–≤**

![–î–ª–∏–Ω–∞ –æ—Ç–∑—ã–≤–∞](./plots/review_length_distribution.png)

### –°–∞–º—ã–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞ –∏ –±–∏–≥—Ä–∞–º–º—ã –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ

![–¢–æ–ø-—Å–ª–æ–≤–∞](./plots/positive_negative_words.png)

### –û–±–ª–∞–∫–∞ —Å–ª–æ–≤ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

- –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ:

![–û–±–ª–∞–∫–æ —Å–ª–æ–≤ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏](./plots/positive_wordcloud.png)

- –ë–∏–≥—Ä–∞–º–º—ã –≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö:

![–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–≥—Ä–∞–º–º—ã](./plots/positive_bigrams_wordcloud.png)

- –ë–∏–≥—Ä–∞–º–º—ã –≤ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö:

![–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –±–∏–≥—Ä–∞–º–º—ã](./plots/negative_bigrams_wordcloud.png)

**–ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –∏–¥–µ–∞–ª–µ–Ω (50/50)**

---

### üîπ –ê–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤

20 —Å–∞–º—ã—Ö —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤ –ø–æ –∫–ª–∞—Å—Å–∞–º:

| Positive | Negative |
|----------|----------|
| great    | bad      |
| best     | worst    |
| love     | boring   |
| story    | waste    |
| ...      | ...      |

---

## –í—ã–≤–æ–¥—ã

- –û–±–∑–æ—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –¥–ª–∏–Ω–µ –≤ —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–∞—Ö
- –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (¬´–ª—É—á—à–∏–π¬ª, ¬´–ø–æ—Ç—Ä—è—Å–∞—é—â–∏–π¬ª, ¬´—Ö—É–¥—à–∏–π¬ª, ¬´—Å–∫—É—á–Ω—ã–π¬ª) —è–≤–ª—è—é—Ç—Å—è —Å–∏–ª—å–Ω—ã–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
- –ë–∏–≥—Ä–∞–º–º—ã, —Ç–∞–∫–∏–µ –∫–∞–∫ ¬´–æ–¥–∏–Ω –ª—É—á—à–∏–π¬ª –∏–ª–∏ ¬´–∫–æ–≥–¥–∞-–ª–∏–±–æ –≤–∏–¥–µ–ª¬ª —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–∞—Ö

---

## –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏

### –ú–æ–¥–µ–ª–∏ TF-IDF
- **–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è**
- **–ú—É–ª—å—Ç–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–π –Ω–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º**

–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä: `TfidfVectorizer(max_features=20000, ngram_range=(1, 2))`

### –ú–æ–¥–µ–ª—å Word2Vec
- –û–±—É—á–µ–Ω–∞ —Å –ø–æ–º–æ—â—å—é `gensim.models.Word2Vec`
- –£—Å—Ä–µ–¥–Ω—ë–Ω–Ω—ã–µ –≤–ª–æ–∂–µ–Ω–∏—è
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: **–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å**

---

## –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏


| Model                            | Accuracy | ROC AUC |
|----------------------------------|----------|---------|
| Logistic Regression (TF-IDF)     | 0.91     | 0.96    |
| Naive Bayes (TF-IDF)             | 0.87     | 0.93    |
| Random Forest (Word2Vec)         | 0.85     | 0.91    |

–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤:
- `td-idf_metrics.json`
- `w2v_metrics.json`

---

## –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

### ROC-–∫—Ä–∏–≤—ã–µ

![–°—Ä–∞–≤–Ω–µ–Ω–∏–µ ROC](./plots/roc_comparison.png)

### –ú–∞—Ç—Ä–∏—Ü—ã –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–µ–π

![–ú–∞—Ç—Ä–∏—Ü—ã –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–µ–π](./plots/conf_matrix.png)

### –°—Ç–æ–ª–±—á–∞—Ç—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã: —Ç–æ—á–Ω–æ—Å—Ç—å –∏ AUC

![–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫](./plots/metric_comparison.png)

---

## –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã

–ú–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ `/models/`:
- `sentiment_model.pkl`
- `tfidf_vectorizer.pkl`
- `td-idf_metrics.json`
- `w2v_clf.pkl`
- `w2v_embedding.model`
- `w2v_metrics.json`

---

## –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- TF-IDF + –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –Ω–∞–∏–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º.
- –ù–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞–µ—Ç—Å—è.
- Word2Vec + —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å ‚Äî –º–Ω–æ–≥–æ–æ–±–µ—â–∞—é—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.
- –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–∞ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

---